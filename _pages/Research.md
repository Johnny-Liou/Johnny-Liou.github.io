---
layout: page
permalink: /Research/
title: Research
description: 
nav: true
nav_order: 2
---

<h2>Current Project</h2>
<ul>
    <li>
        <strong>Hardware Accelerator for Structured Pruning</strong>
        <br>
        Design FPGA-based hardware accelerator for NM pruning
    </li>
</ul>

<!-- <h2>Past Projects</h2>
    <ul>
        <li>Optimizing Compute Core Assignment for Dynamic Batch Inference</li>
        <li>
            <strong>Role of Weight Stationarity for CIM Architecture</strong>
            <p style="text-align: justify;">
            In this work, I focused on the role of weight stationarity in Compute-In-Memory (CIM) systems for BERT-Base and BERT-Large transformer models. I analyzed two architectures: (1) a fully weight-stationary system using Non-Volatile Memory (NVM)-based tiles, which had fast latency but massive area usage, and (2) a partially weight-stationary system that, while lower raw area usage, suffered from higher latency due to the need for reloading weights into Volatile Memory-based tiles. Additionally, I explored alternative architectures for partially weight-stationary systems, identifying design choices that optimized area-compute efficiency (TOPS/sec/sq.mm) across various sequence lengths and input batch sizes.
            </p>
        </li>
        <li>CIM-Aware Post-Training Quantization</li>
    </ul> -->